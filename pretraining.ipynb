{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "NaiEJ7s62dER"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zppwvue-cBuL"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\" # this is needed to get rid of weird colab locale\n",
        "# if you are still running into error, please restart the runtime to initialize a new environment\n",
        "\n",
        "!wget https://zenodo.org/records/7908468/files/python.zip\n",
        "!unzip python.zip\n",
        "!gzip -d python/final/jsonl/train/python_train_0.jsonl.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "\n",
        "def grab_raw_dataset():\n",
        "    raw_dataset = []\n",
        "    file = \"python/final/jsonl/train/python_train_0.jsonl\"\n",
        "    with open(file, \"r\") as f:\n",
        "        raw_dataset.extend([json.loads(x) for x in f.readlines()])\n",
        "    print(\"grabbed data from file {}\".format(file))\n",
        "    print(\"Number of raw functions: {}\".format(len(raw_dataset)))\n",
        "    return raw_dataset\n",
        "\n",
        "raw_dataset = grab_raw_dataset()"
      ],
      "metadata": {
        "id": "w_QmFjfoduda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW, AutoTokenizer, T5ForConditionalGeneration\n",
        "\n",
        "def load_base_model():\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "    return model, tokenizer\n",
        "\n",
        "model, tokenizer = load_base_model()"
      ],
      "metadata": {
        "id": "WrdVC1gA1tTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.encodings['input_ids'].shape[0]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.encodings['input_ids'][i], self.encodings['labels'][i]\n",
        "\n",
        "def prepare_dataset(raw_dataset, tokenizer):\n",
        "    # TODO: complete the implementation of this function\n",
        "    # ....\n",
        "\n",
        "    encodings = {\"input_ids\": input_ids, \"labels\": labels}\n",
        "    dataset = Dataset(encodings)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "ZyvpyT4Z3zzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain the training dataset\n",
        "training_dataset = prepare_dataset(raw_dataset=raw_dataset, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "xirLYNnX343L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train(model, train_dataset, lr, batch_size, num_epochs):\n",
        "\n",
        "  optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    print(\"cuda is available\")\n",
        "    model.cuda()\n",
        "\n",
        "  loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  total_losses = []\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for input_ids, labels in tqdm(loader):\n",
        "        input_ids = input_ids.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        outputs = model(input_ids=input_ids, labels=labels)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "  model.eval()\n",
        "  return model"
      ],
      "metadata": {
        "id": "dOVHXe_ue59n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Apply hyperparameters\n",
        "# NOTE: you may want to use a smaller epoch amount to reduce the time cost of training\n",
        "# NOTE: you may also want to add additional checks to observe the performance of the model\n",
        "# (validation dataset can be found here: https://zenodo.org/records/7908468 with the same format\n",
        "# as the training dataset) they are also already downloaded to this notebook if you have ran\n",
        "# the previous initialization steps\n",
        "\n",
        "batch_size = # TODO\n",
        "learning_rate = # TODO\n",
        "num_epochs = # TODO\n",
        "\n",
        "trained_model = train(model, training_dataset, lr=learning_rate, batch_size=batch_size, num_epochs=num_epochs)"
      ],
      "metadata": {
        "id": "rAN0kxUjtSNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "e22c3ofo6yev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/uiuc-cs598lmz-s24/hw1/main/hw_1_inference_dataset.jsonl"
      ],
      "metadata": {
        "id": "SNrLg3vn7Auo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reload the base model again\n",
        "base_model, _ = load_base_model()"
      ],
      "metadata": {
        "id": "WdjnOkZFCPH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grab_inference_dataset():\n",
        "    inference_dataset = []\n",
        "    file = \"hw_1_inference_dataset.jsonl\"\n",
        "    with open(file, \"r\") as f:\n",
        "        inference_dataset.extend([json.loads(x) for x in f.readlines()])\n",
        "    print(\"grabbed data from file {}\".format(file))\n",
        "    print(\"Number of tasks: {}\".format(len(inference_dataset)))\n",
        "    return inference_dataset\n",
        "\n",
        "inference_dataset = grab_inference_dataset()"
      ],
      "metadata": {
        "id": "fZa0SMz-7ZYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def code_infill(code_model, tokenizer, prefix, suffix):\n",
        "    # TODO: complete the implementation of this function\n",
        "    return model_output\n",
        "\n",
        "\n",
        "def evaluate(code_model, tokenizer, inference_dataset):\n",
        "\n",
        "    def edit_distance(model_output, gt):\n",
        "        # TODO: implement this\n",
        "        return score\n",
        "\n",
        "    ed_scores = []\n",
        "    for data in inference_dataset:\n",
        "\n",
        "        prefix = data['prefix']\n",
        "        suffix = data['suffix']\n",
        "        gt = data['gt']\n",
        "\n",
        "        model_output = code_infill(code_model, tokenizer, prefix, suffix)\n",
        "        ed_scores.append(edit_distance(model_output, gt))\n",
        "\n",
        "    import statistics as st\n",
        "    return st.mean(ed_scores)\n",
        "\n",
        "\n",
        "# Report the results\n",
        "base_model_ed = evaluate(base_model, tokenizer, inference_dataset)\n",
        "trained_model_ed = evaluate(trained_model, tokenizer, inference_dataset)"
      ],
      "metadata": {
        "id": "tzJFinTY7eRu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
